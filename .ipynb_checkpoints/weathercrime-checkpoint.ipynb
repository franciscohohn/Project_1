{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import datetime as dt\n",
    "import json\n",
    "import csv\n",
    "import pytemperature as pyt\n",
    "from pprint import pprint\n",
    "\n",
    "# Import API key\n",
    "from api_keys import api_key\n",
    "\n",
    "# files to Load\n",
    "cpd_crime2018_load = \"Resources/Crimes_-_2018.csv\"\n",
    "cpd_crime2017_load = \"Resources/Crimes_-_2017.csv\"\n",
    "cpd_crime2016_load = \"Resources/Crimes_-_2016.csv\"\n",
    "cpd_crime2015_load = \"Resources/Crimes_-_2015.csv\"\n",
    "cpd_crime2014_load = \"Resources/Crimes_-_2014.csv\"\n",
    "\n",
    "# read CPD crime data and store\n",
    "cpdcrime2018_data = pd.read_csv(cpd_crime2018_load)\n",
    "cpdcrime2017_data = pd.read_csv(cpd_crime2017_load)\n",
    "cpdcrime2016_data = pd.read_csv(cpd_crime2016_load)\n",
    "cpdcrime2015_data = pd.read_csv(cpd_crime2015_load)\n",
    "cpdcrime2014_data = pd.read_csv(cpd_crime2014_load)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull column data and drop NaN \n",
    "cpdcrime2018_data = cpdcrime2018_data[['Date', 'Primary Type']]\n",
    "cpdcrime2018_data = cpdcrime2018_data.dropna(how='any')\n",
    "\n",
    "cpdcrime2017_data = cpdcrime2017_data[['Date', 'Primary Type']]\n",
    "cpdcrime2017_data = cpdcrime2017_data.dropna(how='any')\n",
    "\n",
    "cpdcrime2016_data = cpdcrime2016_data[['Date', 'Primary Type']]\n",
    "cpdcrime2016_data = cpdcrime2016_data.dropna(how='any')\n",
    "\n",
    "cpdcrime2015_data = cpdcrime2015_data[['Date', 'Primary Type']]\n",
    "cpdcrime2015_data = cpdcrime2015_data.dropna(how='any')\n",
    "\n",
    "cpdcrime2014_data = cpdcrime2014_data[['Date', 'Primary Type']]\n",
    "cpdcrime2014_data = cpdcrime2014_data.dropna(how='any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use to check outputs\n",
    "#cpdcrime2018_data.head()\n",
    "#cpdcrime2017_data.head()\n",
    "#cpdcrime2016_data.head()\n",
    "#cpdcrime2015_data.head()\n",
    "#cpdcrime2014_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create series with the date of each reported incident by primary type\n",
    "battery18 = cpdcrime2018_data[cpdcrime2018_data['Primary Type'] == \"BATTERY\"][\"Date\"].reset_index()\n",
    "battery17 = cpdcrime2017_data[cpdcrime2017_data['Primary Type'] == \"BATTERY\"][\"Date\"].reset_index()\n",
    "battery16 = cpdcrime2016_data[cpdcrime2016_data['Primary Type'] == \"BATTERY\"][\"Date\"].reset_index()\n",
    "battery15 = cpdcrime2015_data[cpdcrime2015_data['Primary Type'] == \"BATTERY\"][\"Date\"].reset_index()\n",
    "battery14 = cpdcrime2014_data[cpdcrime2014_data['Primary Type'] == \"BATTERY\"][\"Date\"].reset_index()\n",
    "\n",
    "#format date to be mergeable with weather data \n",
    "battery18['Date'] = pd.to_datetime(battery18['Date']).dt.date\n",
    "battery18['Date'] = pd.to_datetime(battery18['Date'], infer_datetime_format=True)\n",
    "battery17['Date'] = pd.to_datetime(battery17['Date']).dt.date\n",
    "battery17['Date'] = pd.to_datetime(battery17['Date'], infer_datetime_format=True)\n",
    "battery16['Date'] = pd.to_datetime(battery16['Date']).dt.date\n",
    "battery16['Date'] = pd.to_datetime(battery16['Date'], infer_datetime_format=True)\n",
    "battery15['Date'] = pd.to_datetime(battery15['Date']).dt.date\n",
    "battery15['Date'] = pd.to_datetime(battery15['Date'], infer_datetime_format=True)\n",
    "battery14['Date'] = pd.to_datetime(battery14['Date']).dt.date\n",
    "battery14['Date'] = pd.to_datetime(battery14['Date'], infer_datetime_format=True)\n",
    "\n",
    "#sort date data for chronological order\n",
    "battery18.sort_values(\"Date\", inplace=True)\n",
    "battery17.sort_values(\"Date\", inplace=True)\n",
    "battery16.sort_values(\"Date\", inplace=True)\n",
    "battery15.sort_values(\"Date\", inplace=True)\n",
    "battery14.sort_values(\"Date\", inplace=True)\n",
    "\n",
    "#create number of reported incidents by date \n",
    "battery18['Reported Incidents'] = battery18['Date'].map(battery18['Date'].value_counts())\n",
    "battery17['Reported Incidents'] = battery17['Date'].map(battery17['Date'].value_counts())\n",
    "battery16['Reported Incidents'] = battery16['Date'].map(battery16['Date'].value_counts())\n",
    "battery15['Reported Incidents'] = battery15['Date'].map(battery15['Date'].value_counts())\n",
    "battery14['Reported Incidents'] = battery14['Date'].map(battery14['Date'].value_counts())\n",
    "\n",
    "#set index to date and drop duplicate data\n",
    "battery18.set_index('Date')\n",
    "battery18.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "battery17.set_index('Date')\n",
    "battery17.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "battery16.set_index('Date')\n",
    "battery16.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "battery15.set_index('Date')\n",
    "battery15.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "battery14.set_index('Date')\n",
    "battery14.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "\n",
    "#delete unnecessary index column\n",
    "del battery18['index']\n",
    "del battery17['index']\n",
    "del battery16['index']\n",
    "del battery15['index']\n",
    "del battery14['index']\n",
    "\n",
    "#merge all reported battery incidents for all five years\n",
    "battery_all = battery18.append([battery17, battery16, battery15, battery14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use to check output\n",
    "#battery18\n",
    "#battery18.dtypes\n",
    "#battery17\n",
    "#battery17.dtypes\n",
    "#battery16\n",
    "#battery16.dtypes\n",
    "#battery15\n",
    "#battery15.dtypes\n",
    "#battery14\n",
    "#battery14.dtypes\n",
    "#battery_all\n",
    "#battery_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create series with the date of each reported incident by primary type\n",
    "csa18 = cpdcrime2018_data[cpdcrime2018_data['Primary Type'] == \"CRIM SEXUAL ASSAULT\"][\"Date\"].reset_index()\n",
    "csa17 = cpdcrime2017_data[cpdcrime2017_data['Primary Type'] == \"CRIM SEXUAL ASSAULT\"][\"Date\"].reset_index()\n",
    "csa16 = cpdcrime2016_data[cpdcrime2016_data['Primary Type'] == \"CRIM SEXUAL ASSAULT\"][\"Date\"].reset_index()\n",
    "csa15 = cpdcrime2015_data[cpdcrime2015_data['Primary Type'] == \"CRIM SEXUAL ASSAULT\"][\"Date\"].reset_index()\n",
    "csa14 = cpdcrime2014_data[cpdcrime2014_data['Primary Type'] == \"CRIM SEXUAL ASSAULT\"][\"Date\"].reset_index()\n",
    "\n",
    "#format date in dataframe to be mergeable with weather data \n",
    "csa18['Date'] = pd.to_datetime(csa18['Date']).dt.date\n",
    "csa18['Date'] = pd.to_datetime(csa18['Date'], infer_datetime_format=True)\n",
    "csa17['Date'] = pd.to_datetime(csa17['Date']).dt.date\n",
    "csa17['Date'] = pd.to_datetime(csa17['Date'], infer_datetime_format=True)\n",
    "csa16['Date'] = pd.to_datetime(csa16['Date']).dt.date\n",
    "csa16['Date'] = pd.to_datetime(csa16['Date'], infer_datetime_format=True)\n",
    "csa15['Date'] = pd.to_datetime(csa15['Date']).dt.date\n",
    "csa15['Date'] = pd.to_datetime(csa15['Date'], infer_datetime_format=True)\n",
    "csa14['Date'] = pd.to_datetime(csa14['Date']).dt.date\n",
    "csa14['Date'] = pd.to_datetime(csa14['Date'], infer_datetime_format=True)\n",
    "\n",
    "#sort date data for chronological order\n",
    "csa18.sort_values(\"Date\", inplace=True)\n",
    "csa17.sort_values(\"Date\", inplace=True)\n",
    "csa16.sort_values(\"Date\", inplace=True)\n",
    "csa15.sort_values(\"Date\", inplace=True)\n",
    "csa14.sort_values(\"Date\", inplace=True)\n",
    "\n",
    "#create number of reported incidents by date \n",
    "csa18['Reported Incidents'] = csa18['Date'].map(csa18['Date'].value_counts())\n",
    "csa17['Reported Incidents'] = csa17['Date'].map(csa17['Date'].value_counts())\n",
    "csa16['Reported Incidents'] = csa16['Date'].map(csa16['Date'].value_counts())\n",
    "csa15['Reported Incidents'] = csa15['Date'].map(csa15['Date'].value_counts())\n",
    "csa14['Reported Incidents'] = csa14['Date'].map(csa14['Date'].value_counts())\n",
    "\n",
    "#set index to date and drop duplicate data\n",
    "csa18.set_index('Date')\n",
    "csa18.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "csa17.set_index('Date')\n",
    "csa17.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "csa16.set_index('Date')\n",
    "csa16.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "csa15.set_index('Date')\n",
    "csa15.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "csa14.set_index('Date')\n",
    "csa14.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "\n",
    "\n",
    "#delete unnecessary index column\n",
    "del csa18['index']\n",
    "del csa17['index']\n",
    "del csa16['index']\n",
    "del csa15['index']\n",
    "del csa14['index']\n",
    "\n",
    "#merge all reported criminal sexual assault incidents for all five years\n",
    "csa_all = csa18.append([csa17, csa16, csa15, csa14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use to check output\n",
    "#csa18\n",
    "#csa18.dtypes\n",
    "#csa17\n",
    "#csa17.dtypes\n",
    "#csa16\n",
    "#csa16.dtypes\n",
    "#csa15\n",
    "#csa15.dtypes\n",
    "#csa14\n",
    "#csa14.dtypes\n",
    "#csa_all\n",
    "#csa_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create series with the date of each reported incident by primary type\n",
    "homicide18 = cpdcrime2018_data[cpdcrime2018_data['Primary Type'] == \"HOMICIDE\"][\"Date\"].reset_index()\n",
    "homicide17 = cpdcrime2017_data[cpdcrime2017_data['Primary Type'] == \"HOMICIDE\"][\"Date\"].reset_index()\n",
    "homicide16 = cpdcrime2016_data[cpdcrime2016_data['Primary Type'] == \"HOMICIDE\"][\"Date\"].reset_index()\n",
    "homicide15 = cpdcrime2015_data[cpdcrime2015_data['Primary Type'] == \"HOMICIDE\"][\"Date\"].reset_index()\n",
    "homicide14 = cpdcrime2014_data[cpdcrime2014_data['Primary Type'] == \"HOMICIDE\"][\"Date\"].reset_index()\n",
    "\n",
    "#format date in dataframe to be mergeable with weather data \n",
    "homicide18['Date'] = pd.to_datetime(homicide18['Date']).dt.date\n",
    "homicide18['Date'] = pd.to_datetime(homicide18['Date'], infer_datetime_format=True)\n",
    "homicide17['Date'] = pd.to_datetime(homicide17['Date']).dt.date\n",
    "homicide17['Date'] = pd.to_datetime(homicide17['Date'], infer_datetime_format=True)\n",
    "homicide16['Date'] = pd.to_datetime(homicide16['Date']).dt.date\n",
    "homicide16['Date'] = pd.to_datetime(homicide16['Date'], infer_datetime_format=True)\n",
    "homicide15['Date'] = pd.to_datetime(homicide15['Date']).dt.date\n",
    "homicide15['Date'] = pd.to_datetime(homicide15['Date'], infer_datetime_format=True)\n",
    "homicide14['Date'] = pd.to_datetime(homicide14['Date']).dt.date\n",
    "homicide14['Date'] = pd.to_datetime(homicide14['Date'], infer_datetime_format=True)\n",
    "\n",
    "#sort date data for chronological order\n",
    "homicide18.sort_values(\"Date\", inplace=True)\n",
    "homicide17.sort_values(\"Date\", inplace=True)\n",
    "homicide16.sort_values(\"Date\", inplace=True)\n",
    "homicide15.sort_values(\"Date\", inplace=True)\n",
    "homicide14.sort_values(\"Date\", inplace=True)\n",
    "\n",
    "#create number of reported incidents by date \n",
    "homicide18['Reported Incidents'] = homicide18['Date'].map(homicide18['Date'].value_counts())\n",
    "homicide17['Reported Incidents'] = homicide17['Date'].map(homicide17['Date'].value_counts())\n",
    "homicide16['Reported Incidents'] = homicide16['Date'].map(homicide16['Date'].value_counts())\n",
    "homicide15['Reported Incidents'] = homicide15['Date'].map(homicide15['Date'].value_counts())\n",
    "homicide14['Reported Incidents'] = homicide14['Date'].map(homicide14['Date'].value_counts())\n",
    "\n",
    "#set index to date and drop duplicate data\n",
    "homicide18.set_index('Date')\n",
    "homicide18.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "homicide17.set_index('Date')\n",
    "homicide17.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "homicide16.set_index('Date')\n",
    "homicide16.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "homicide15.set_index('Date')\n",
    "homicide15.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "homicide14.set_index('Date')\n",
    "homicide14.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "\n",
    "\n",
    "#delete unnecessary index column\n",
    "del homicide18['index']\n",
    "del homicide17['index']\n",
    "del homicide16['index']\n",
    "del homicide15['index']\n",
    "del homicide14['index']\n",
    "\n",
    "\n",
    "#merge all reported homicide incidents for all five years\n",
    "homicide_all = homicide18.append([homicide17, homicide16, homicide15, homicide14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use to check output\n",
    "#homicide18\n",
    "#homicide18.dtypes\n",
    "#homicide17\n",
    "#homicide17.dtypes\n",
    "#homicide16\n",
    "#homicide16.dtypes\n",
    "#homicide15\n",
    "#homicide15.dtypes\n",
    "#homicide14\n",
    "#homicide14.dtypes\n",
    "#homicide_all\n",
    "#homicide_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create series with the date of each reported incident by primary type\n",
    "robbery18 = cpdcrime2018_data[cpdcrime2018_data['Primary Type'] == \"ROBBERY\"][\"Date\"].reset_index()\n",
    "robbery17 = cpdcrime2017_data[cpdcrime2017_data['Primary Type'] == \"ROBBERY\"][\"Date\"].reset_index()\n",
    "robbery16 = cpdcrime2016_data[cpdcrime2016_data['Primary Type'] == \"ROBBERY\"][\"Date\"].reset_index()\n",
    "robbery15 = cpdcrime2015_data[cpdcrime2015_data['Primary Type'] == \"ROBBERY\"][\"Date\"].reset_index()\n",
    "robbery14 = cpdcrime2014_data[cpdcrime2014_data['Primary Type'] == \"ROBBERY\"][\"Date\"].reset_index()\n",
    "\n",
    "#format date in dataframe to be mergeable with weather data \n",
    "robbery18['Date'] = pd.to_datetime(robbery18['Date']).dt.date\n",
    "robbery18['Date'] = pd.to_datetime(robbery18['Date'], infer_datetime_format=True)\n",
    "robbery17['Date'] = pd.to_datetime(robbery17['Date']).dt.date\n",
    "robbery17['Date'] = pd.to_datetime(robbery17['Date'], infer_datetime_format=True)\n",
    "robbery16['Date'] = pd.to_datetime(robbery16['Date']).dt.date\n",
    "robbery16['Date'] = pd.to_datetime(robbery16['Date'], infer_datetime_format=True)\n",
    "robbery15['Date'] = pd.to_datetime(robbery15['Date']).dt.date\n",
    "robbery15['Date'] = pd.to_datetime(robbery15['Date'], infer_datetime_format=True)\n",
    "robbery14['Date'] = pd.to_datetime(robbery14['Date']).dt.date\n",
    "robbery14['Date'] = pd.to_datetime(robbery14['Date'], infer_datetime_format=True)\n",
    "\n",
    "#sort date data for chronological order\n",
    "robbery18.sort_values(\"Date\", inplace=True)\n",
    "robbery17.sort_values(\"Date\", inplace=True)\n",
    "robbery16.sort_values(\"Date\", inplace=True)\n",
    "robbery15.sort_values(\"Date\", inplace=True)\n",
    "robbery14.sort_values(\"Date\", inplace=True)\n",
    "\n",
    "#create number of reported incidents by date \n",
    "robbery18['Reported Incidents'] = robbery18['Date'].map(robbery18['Date'].value_counts())\n",
    "robbery17['Reported Incidents'] = robbery17['Date'].map(robbery17['Date'].value_counts())\n",
    "robbery16['Reported Incidents'] = robbery16['Date'].map(robbery16['Date'].value_counts())\n",
    "robbery15['Reported Incidents'] = robbery15['Date'].map(robbery15['Date'].value_counts())\n",
    "robbery14['Reported Incidents'] = robbery14['Date'].map(robbery14['Date'].value_counts())\n",
    "\n",
    "#set index to date and drop duplicate data\n",
    "robbery18.set_index('Date')\n",
    "robbery18.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "robbery17.set_index('Date')\n",
    "robbery17.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "robbery16.set_index('Date')\n",
    "robbery16.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "robbery15.set_index('Date')\n",
    "robbery15.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "robbery14.set_index('Date')\n",
    "robbery14.drop_duplicates(subset =\"Date\", keep = 'first', inplace = True)\n",
    "\n",
    "#delete unnecessary index column\n",
    "del robbery18['index']\n",
    "del robbery17['index']\n",
    "del robbery16['index']\n",
    "del robbery15['index']\n",
    "del robbery14['index']\n",
    "\n",
    "#merge all reported robbery incidents for all five years\n",
    "robbery_all = robbery18.append([robbery17, robbery16, robbery15, robbery14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use to check output\n",
    "#robbery18\n",
    "#robbery18.dtypes\n",
    "#robbery17\n",
    "#robbery17.dtypes\n",
    "#robbery16\n",
    "#robbery16.dtypes\n",
    "#robbery15\n",
    "#robbery15.dtypes\n",
    "#robbery14\n",
    "#robbery14.dtypes\n",
    "#robbery_all\n",
    "#robbery_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#begin OpenWeatherMap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datetime = []\n",
    "Max_Temp = []\n",
    "Humidity = []\n",
    "Cloudiness = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"weather_data.json\")\n",
    "json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in json_data[\"values\"]:\n",
    "        Datetime.append(each[\"dt\"])\n",
    "        Max_Temp.append(each[\"main\"][\"temp_max\"])\n",
    "        Humidity.append(each[\"main\"][\"humidity\"])\n",
    "        Cloudiness.append(each[\"clouds\"][\"all\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Max_Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Cloudiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1349096400</td>\n",
       "      <td>287.59</td>\n",
       "      <td>71</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1349186400</td>\n",
       "      <td>288.71</td>\n",
       "      <td>62</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1349190000</td>\n",
       "      <td>290.37</td>\n",
       "      <td>51</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1349193600</td>\n",
       "      <td>290.93</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1349197200</td>\n",
       "      <td>292.04</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Datetime  Max_Temp  Humidity  Cloudiness\n",
       "0  1349096400    287.59        71          90\n",
       "1  1349186400    288.71        62          90\n",
       "2  1349190000    290.37        51          90\n",
       "3  1349193600    290.93         0          92\n",
       "4  1349197200    292.04         0          92"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df1 = pd.DataFrame({\"Datetime\": Datetime,\n",
    "                            \"Max_Temp\": Max_Temp,\n",
    "                            \"Humidity\": Humidity,\n",
    "                            \"Cloudiness\": Cloudiness})\n",
    "\n",
    "weather_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Max_Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Cloudiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>287.59</td>\n",
       "      <td>71</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-02 14:00:00</td>\n",
       "      <td>288.71</td>\n",
       "      <td>62</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-02 15:00:00</td>\n",
       "      <td>290.37</td>\n",
       "      <td>51</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-02 16:00:00</td>\n",
       "      <td>290.93</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-02 17:00:00</td>\n",
       "      <td>292.04</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Datetime  Max_Temp  Humidity  Cloudiness\n",
       "0 2012-10-01 13:00:00    287.59        71          90\n",
       "1 2012-10-02 14:00:00    288.71        62          90\n",
       "2 2012-10-02 15:00:00    290.37        51          90\n",
       "3 2012-10-02 16:00:00    290.93         0          92\n",
       "4 2012-10-02 17:00:00    292.04         0          92"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df1[\"Datetime\"]=pd.to_datetime(weather_df1[\"Datetime\"],unit='s')\n",
    "weather_df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Max_Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Cloudiness</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>287.59</td>\n",
       "      <td>71</td>\n",
       "      <td>90</td>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-02 14:00:00</td>\n",
       "      <td>288.71</td>\n",
       "      <td>62</td>\n",
       "      <td>90</td>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>2012-10-02 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-02 15:00:00</td>\n",
       "      <td>290.37</td>\n",
       "      <td>51</td>\n",
       "      <td>90</td>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>2012-10-02 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-02 16:00:00</td>\n",
       "      <td>290.93</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>2012-10-02 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-02 17:00:00</td>\n",
       "      <td>292.04</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>2012-10-02 17:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Datetime  Max_Temp  Humidity  Cloudiness       Date  \\\n",
       "0 2012-10-01 13:00:00    287.59        71          90 2012-10-01   \n",
       "1 2012-10-02 14:00:00    288.71        62          90 2012-10-02   \n",
       "2 2012-10-02 15:00:00    290.37        51          90 2012-10-02   \n",
       "3 2012-10-02 16:00:00    290.93         0          92 2012-10-02   \n",
       "4 2012-10-02 17:00:00    292.04         0          92 2012-10-02   \n",
       "\n",
       "                 Time  \n",
       "0 2012-10-01 13:00:00  \n",
       "1 2012-10-02 14:00:00  \n",
       "2 2012-10-02 15:00:00  \n",
       "3 2012-10-02 16:00:00  \n",
       "4 2012-10-02 17:00:00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df1[\"Date\"] = pd.to_datetime(weather_df1['Datetime']).dt.date\n",
    "weather_df1[\"Date\"] = pd.to_datetime(weather_df1['Date'], infer_datetime_format=True)\n",
    "weather_df1[\"Time\"] = pd.to_datetime(weather_df1['Datetime']).dt.time\n",
    "weather_df1[\"Time\"] = pd.to_datetime(weather_df1['Datetime'], infer_datetime_format=True)\n",
    "\n",
    "\n",
    "weather_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Max_Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Cloudiness</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Max_Temp_(F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>287.59</td>\n",
       "      <td>71</td>\n",
       "      <td>90</td>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>57.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-02 14:00:00</td>\n",
       "      <td>288.71</td>\n",
       "      <td>62</td>\n",
       "      <td>90</td>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>2012-10-02 14:00:00</td>\n",
       "      <td>59.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-02 15:00:00</td>\n",
       "      <td>290.37</td>\n",
       "      <td>51</td>\n",
       "      <td>90</td>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>2012-10-02 15:00:00</td>\n",
       "      <td>62.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-02 16:00:00</td>\n",
       "      <td>290.93</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>2012-10-02 16:00:00</td>\n",
       "      <td>63.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-02 17:00:00</td>\n",
       "      <td>292.04</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>2012-10-02 17:00:00</td>\n",
       "      <td>65.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Datetime  Max_Temp  Humidity  Cloudiness       Date  \\\n",
       "0 2012-10-01 13:00:00    287.59        71          90 2012-10-01   \n",
       "1 2012-10-02 14:00:00    288.71        62          90 2012-10-02   \n",
       "2 2012-10-02 15:00:00    290.37        51          90 2012-10-02   \n",
       "3 2012-10-02 16:00:00    290.93         0          92 2012-10-02   \n",
       "4 2012-10-02 17:00:00    292.04         0          92 2012-10-02   \n",
       "\n",
       "                 Time  Max_Temp_(F)  \n",
       "0 2012-10-01 13:00:00         57.97  \n",
       "1 2012-10-02 14:00:00         59.99  \n",
       "2 2012-10-02 15:00:00         62.98  \n",
       "3 2012-10-02 16:00:00         63.98  \n",
       "4 2012-10-02 17:00:00         65.98  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df1[\"Max_Temp_(F)\"]=pyt.k2f(weather_df1[\"Max_Temp\"])\n",
    "weather_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Cloudiness</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Max_Temp_(F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>90</td>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>57.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>90</td>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>2012-10-02 14:00:00</td>\n",
       "      <td>59.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>90</td>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>2012-10-02 15:00:00</td>\n",
       "      <td>62.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>2012-10-02 16:00:00</td>\n",
       "      <td>63.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>2012-10-02 17:00:00</td>\n",
       "      <td>65.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Humidity  Cloudiness       Date                Time  Max_Temp_(F)\n",
       "0        71          90 2012-10-01 2012-10-01 13:00:00         57.97\n",
       "1        62          90 2012-10-02 2012-10-02 14:00:00         59.99\n",
       "2        51          90 2012-10-02 2012-10-02 15:00:00         62.98\n",
       "3         0          92 2012-10-02 2012-10-02 16:00:00         63.98\n",
       "4         0          92 2012-10-02 2012-10-02 17:00:00         65.98"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del weather_df1['Datetime']\n",
    "del weather_df1[\"Max_Temp\"]\n",
    "del weather_df1[\"Datetime\"]\n",
    "weather_df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Humidity', 'Cloudiness', 'Max_Temp_(F)'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df2 = pd.DataFrame(weather_df1.groupby(\"Date\")[\"Humidity\", \"Cloudiness\", \"Max_Temp_(F)\"].mean())\n",
    "weather_df2.head()\n",
    "weather_df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Humidity        71.208333\n",
       "Cloudiness      66.750000\n",
       "Max_Temp_(F)    75.662500\n",
       "Name: 2014-07-26 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime('2014-10-14')\n",
    "weather_df2.loc[pd.to_datetime('2014-07-26')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#begin merging CPD crime data with weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine weather data into crime incident data for final dataframes\n",
    "weatherbattery18 = battery18.merge(weather_df2, how='left', on='Date')\n",
    "weatherbattery17 = battery17.merge(weather_df2, how='left', on='Date')\n",
    "weatherbattery16 = battery16.merge(weather_df2, how='left', on='Date')\n",
    "weatherbattery15 = battery15.merge(weather_df2, how='left', on='Date')\n",
    "weatherbattery14 = battery14.merge(weather_df2, how='left', on='Date')\n",
    "weatherbatteryall = battery_all.merge(weather_df2, how='left', on='Date')\n",
    "\n",
    "#calculate number of NaN values then drop them\n",
    "weatherbattery18nan = pd.isnull(weatherbattery18).sum()\n",
    "weatherbattery18 = weatherbattery18.dropna(how='any')\n",
    "weatherbattery17nan = pd.isnull(weatherbattery17).sum()\n",
    "weatherbattery17 = weatherbattery17.dropna(how='any')\n",
    "weatherbattery16nan = pd.isnull(weatherbattery16).sum()\n",
    "weatherbattery16 = weatherbattery16.dropna(how='any')\n",
    "weatherbattery15nan = pd.isnull(weatherbattery15).sum()\n",
    "weatherbattery15 = weatherbattery15.dropna(how='any')\n",
    "weatherbattery14nan = pd.isnull(weatherbattery14).sum()\n",
    "weatherbattery14 = weatherbattery14.dropna(how='any')\n",
    "weatherbatteryallnan = pd.isnull(weatherbatteryall).sum()\n",
    "weatherbatteryall = weatherbatteryall.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use to check outputs\n",
    "#weatherbattery18nan\n",
    "#weatherbattery18\n",
    "#weatherbattery17nan\n",
    "#weatherbattery17\n",
    "#weatherbattery16nan\n",
    "#weatherbattery16\n",
    "#weatherbattery15nan\n",
    "#weatherbattery15\n",
    "#weatherbattery14nan\n",
    "#weatherbattery14\n",
    "#weatherbatteryallnan\n",
    "#weatherbatteryall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine weather data into crime incident data for final dataframes\n",
    "weathercsa18 = csa18.merge(weather_df2, how='left', on='Date')\n",
    "weathercsa17 = csa17.merge(weather_df2, how='left', on='Date')\n",
    "weathercsa16 = csa16.merge(weather_df2, how='left', on='Date')\n",
    "weathercsa15 = csa15.merge(weather_df2, how='left', on='Date')\n",
    "weathercsa14 = csa14.merge(weather_df2, how='left', on='Date')\n",
    "weathercsaall = csa_all.merge(weather_df2, how='left', on='Date')\n",
    "\n",
    "#calculate number of NaN values then drop them\n",
    "weathercsa18nan = pd.isnull(weathercsa18).sum()\n",
    "weathercsa18 = weathercsa18.dropna(how='any')\n",
    "weathercsa17nan = pd.isnull(weathercsa17).sum()\n",
    "weathercsa17 = weathercsa17.dropna(how='any')\n",
    "weathercsa16nan = pd.isnull(weathercsa16).sum()\n",
    "weathercsa16 = weathercsa16.dropna(how='any')\n",
    "weathercsa15nan = pd.isnull(weathercsa15).sum()\n",
    "weathercsa15 = weathercsa15.dropna(how='any')\n",
    "weathercsa14nan = pd.isnull(weathercsa14).sum()\n",
    "weathercsa14 = weathercsa14.dropna(how='any')\n",
    "weathercsaallnan = pd.isnull(weathercsaall).sum()\n",
    "weathercsaall = weathercsaall.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use to check outputs\n",
    "#weathercsa18nan\n",
    "#weathercsa18\n",
    "#weathercsa17nan\n",
    "#weathercsa17\n",
    "#weathercsa16nan\n",
    "#weathercsa16\n",
    "#weathercsa15nan\n",
    "#weathercsa15\n",
    "#weathercsa14nan\n",
    "#weathercsa14\n",
    "#weathercsaallnan\n",
    "#weathercsaall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine weather data into crime incident data for final dataframes\n",
    "weatherhomicide18 = homicide18.merge(weather_df2, how='left', on='Date')\n",
    "weatherhomicide17 = homicide17.merge(weather_df2, how='left', on='Date')\n",
    "weatherhomicide16 = homicide16.merge(weather_df2, how='left', on='Date')\n",
    "weatherhomicide15 = homicide15.merge(weather_df2, how='left', on='Date')\n",
    "weatherhomicide14 = homicide14.merge(weather_df2, how='left', on='Date')\n",
    "weatherhomicideall = homicide_all.merge(weather_df2, how='left', on='Date')\n",
    "\n",
    "#calculate number of NaN values then drop them\n",
    "weatherhomicide18nan = pd.isnull(weatherhomicide18).sum()\n",
    "weatherhomicide18 = weatherhomicide18.dropna(how='any')\n",
    "weatherhomicide17nan = pd.isnull(weatherhomicide17).sum()\n",
    "weatherhomicide17 = weatherhomicide17.dropna(how='any')\n",
    "weatherhomicide16nan = pd.isnull(weatherhomicide16).sum()\n",
    "weatherhomicide16 = weatherhomicide16.dropna(how='any')\n",
    "weatherhomicide15nan = pd.isnull(weatherhomicide15).sum()\n",
    "weatherhomicide15 = weatherhomicide15.dropna(how='any')\n",
    "weatherhomicide14nan = pd.isnull(weatherhomicide14).sum()\n",
    "weatherhomicide14 = weatherhomicide14.dropna(how='any')\n",
    "weatherhomicideallnan = pd.isnull(weatherhomicideall).sum()\n",
    "weatherhomicideall = weatherhomicideall.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use to check outputs\n",
    "#weatherhomicide18nan\n",
    "#weatherhomicide18\n",
    "#weatherhomicide17nan\n",
    "#weatherhomicide17\n",
    "#weatherhomicide16nan\n",
    "#weatherhomicide16\n",
    "#weatherhomicide15nan\n",
    "#weatherhomicide15\n",
    "#weatherhomicide14nan\n",
    "#weatherhomicide14\n",
    "#weatherhomicideallnan\n",
    "#weatherhomicideall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine weather data into crime incident data for final dataframes\n",
    "weatherrobbery18 = robbery18.merge(weather_df2, how='left', on='Date')\n",
    "weatherrobbery17 = robbery17.merge(weather_df2, how='left', on='Date')\n",
    "weatherrobbery16 = robbery16.merge(weather_df2, how='left', on='Date')\n",
    "weatherrobbery15 = robbery15.merge(weather_df2, how='left', on='Date')\n",
    "weatherrobbery14 = robbery14.merge(weather_df2, how='left', on='Date')\n",
    "weatherrobberyall = robbery_all.merge(weather_df2, how='left', on='Date')\n",
    "\n",
    "#calculate number of NaN values then drop them\n",
    "weatherrobbery18nan = pd.isnull(weatherrobbery18).sum()\n",
    "weatherrobbery18 = weatherrobbery18.dropna(how='any')\n",
    "weatherrobbery17nan = pd.isnull(weatherrobbery17).sum()\n",
    "weatherrobbery17 = weatherrobbery17.dropna(how='any')\n",
    "weatherrobbery16nan = pd.isnull(weatherrobbery16).sum()\n",
    "weatherrobbery16 = weatherrobbery16.dropna(how='any')\n",
    "weatherrobbery15nan = pd.isnull(weatherrobbery15).sum()\n",
    "weatherrobbery15 = weatherrobbery15.dropna(how='any')\n",
    "weatherrobbery14nan = pd.isnull(weatherrobbery14).sum()\n",
    "weatherrobbery14 = weatherrobbery14.dropna(how='any')\n",
    "weatherrobberyallnan = pd.isnull(weatherrobberyall).sum()\n",
    "weatherrobberyall = weatherrobberyall.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Reported Incidents</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Cloudiness</th>\n",
       "      <th>Max_Temp_(F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>30</td>\n",
       "      <td>54.291667</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>2.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>28</td>\n",
       "      <td>66.750000</td>\n",
       "      <td>6.458333</td>\n",
       "      <td>-0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>37</td>\n",
       "      <td>66.833333</td>\n",
       "      <td>60.416667</td>\n",
       "      <td>12.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>32</td>\n",
       "      <td>60.125000</td>\n",
       "      <td>31.208333</td>\n",
       "      <td>11.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>34</td>\n",
       "      <td>59.750000</td>\n",
       "      <td>11.708333</td>\n",
       "      <td>7.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>24</td>\n",
       "      <td>54.833333</td>\n",
       "      <td>11.625000</td>\n",
       "      <td>8.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>41</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.958333</td>\n",
       "      <td>17.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>37</td>\n",
       "      <td>86.875000</td>\n",
       "      <td>71.333333</td>\n",
       "      <td>35.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>32</td>\n",
       "      <td>91.375000</td>\n",
       "      <td>54.708333</td>\n",
       "      <td>32.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>32</td>\n",
       "      <td>93.208333</td>\n",
       "      <td>81.958333</td>\n",
       "      <td>38.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>25</td>\n",
       "      <td>89.125000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>57.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>42</td>\n",
       "      <td>84.458333</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>30.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-13</td>\n",
       "      <td>30</td>\n",
       "      <td>67.166667</td>\n",
       "      <td>56.791667</td>\n",
       "      <td>17.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>32</td>\n",
       "      <td>67.291667</td>\n",
       "      <td>20.166667</td>\n",
       "      <td>13.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>21</td>\n",
       "      <td>82.958333</td>\n",
       "      <td>84.208333</td>\n",
       "      <td>20.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>24</td>\n",
       "      <td>76.916667</td>\n",
       "      <td>86.875000</td>\n",
       "      <td>17.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-17</td>\n",
       "      <td>19</td>\n",
       "      <td>79.125000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>16.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>22</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>14.826087</td>\n",
       "      <td>22.353913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>25</td>\n",
       "      <td>67.708333</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>32.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>34</td>\n",
       "      <td>71.958333</td>\n",
       "      <td>28.083333</td>\n",
       "      <td>40.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>36</td>\n",
       "      <td>91.041667</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>42.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>29</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>50.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>34</td>\n",
       "      <td>90.791667</td>\n",
       "      <td>73.291667</td>\n",
       "      <td>38.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>20</td>\n",
       "      <td>82.833333</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>30.255000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>26</td>\n",
       "      <td>76.958333</td>\n",
       "      <td>46.125000</td>\n",
       "      <td>33.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>27</td>\n",
       "      <td>78.750000</td>\n",
       "      <td>16.041667</td>\n",
       "      <td>44.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-01-27</td>\n",
       "      <td>26</td>\n",
       "      <td>49.833333</td>\n",
       "      <td>64.208333</td>\n",
       "      <td>50.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>27</td>\n",
       "      <td>77.291667</td>\n",
       "      <td>23.291667</td>\n",
       "      <td>38.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>24</td>\n",
       "      <td>81.666667</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>31.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>20</td>\n",
       "      <td>69.041667</td>\n",
       "      <td>32.041667</td>\n",
       "      <td>23.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>2014-07-08</td>\n",
       "      <td>36</td>\n",
       "      <td>62.130435</td>\n",
       "      <td>64.347826</td>\n",
       "      <td>78.697391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>2014-07-09</td>\n",
       "      <td>25</td>\n",
       "      <td>58.833333</td>\n",
       "      <td>32.208333</td>\n",
       "      <td>73.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>2014-07-10</td>\n",
       "      <td>36</td>\n",
       "      <td>66.333333</td>\n",
       "      <td>17.625000</td>\n",
       "      <td>71.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>2014-07-11</td>\n",
       "      <td>38</td>\n",
       "      <td>50.260870</td>\n",
       "      <td>47.521739</td>\n",
       "      <td>73.552609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>2014-07-12</td>\n",
       "      <td>32</td>\n",
       "      <td>70.125000</td>\n",
       "      <td>82.916667</td>\n",
       "      <td>76.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>2014-07-13</td>\n",
       "      <td>24</td>\n",
       "      <td>74.833333</td>\n",
       "      <td>66.875000</td>\n",
       "      <td>78.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>32</td>\n",
       "      <td>61.227273</td>\n",
       "      <td>56.181818</td>\n",
       "      <td>75.343636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>2014-07-15</td>\n",
       "      <td>22</td>\n",
       "      <td>62.458333</td>\n",
       "      <td>53.750000</td>\n",
       "      <td>65.744583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>2014-07-16</td>\n",
       "      <td>37</td>\n",
       "      <td>70.583333</td>\n",
       "      <td>51.583333</td>\n",
       "      <td>65.755833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>2014-07-17</td>\n",
       "      <td>14</td>\n",
       "      <td>62.625000</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>68.547917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>2014-07-18</td>\n",
       "      <td>22</td>\n",
       "      <td>61.083333</td>\n",
       "      <td>52.583333</td>\n",
       "      <td>72.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>2014-07-19</td>\n",
       "      <td>33</td>\n",
       "      <td>55.208333</td>\n",
       "      <td>26.083333</td>\n",
       "      <td>74.146250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>2014-07-20</td>\n",
       "      <td>30</td>\n",
       "      <td>64.541667</td>\n",
       "      <td>49.250000</td>\n",
       "      <td>75.360417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>2014-07-21</td>\n",
       "      <td>26</td>\n",
       "      <td>66.750000</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>78.529583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>2014-07-22</td>\n",
       "      <td>35</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>19.291667</td>\n",
       "      <td>81.830417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>2014-07-23</td>\n",
       "      <td>33</td>\n",
       "      <td>70.791667</td>\n",
       "      <td>45.875000</td>\n",
       "      <td>75.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>2014-07-24</td>\n",
       "      <td>31</td>\n",
       "      <td>68.125000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>64.928750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>2014-07-25</td>\n",
       "      <td>32</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>63.055556</td>\n",
       "      <td>68.667778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>2014-07-26</td>\n",
       "      <td>24</td>\n",
       "      <td>71.208333</td>\n",
       "      <td>66.750000</td>\n",
       "      <td>75.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>2014-07-27</td>\n",
       "      <td>23</td>\n",
       "      <td>70.714286</td>\n",
       "      <td>49.904762</td>\n",
       "      <td>80.236667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>23</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>79.082000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>33</td>\n",
       "      <td>62.782609</td>\n",
       "      <td>17.869565</td>\n",
       "      <td>73.829130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>38</td>\n",
       "      <td>66.227273</td>\n",
       "      <td>49.409091</td>\n",
       "      <td>77.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>2014-08-02</td>\n",
       "      <td>42</td>\n",
       "      <td>72.250000</td>\n",
       "      <td>23.750000</td>\n",
       "      <td>69.526250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>2014-08-03</td>\n",
       "      <td>26</td>\n",
       "      <td>47.875000</td>\n",
       "      <td>68.125000</td>\n",
       "      <td>85.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>2014-08-04</td>\n",
       "      <td>31</td>\n",
       "      <td>61.714286</td>\n",
       "      <td>52.333333</td>\n",
       "      <td>78.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>2014-08-05</td>\n",
       "      <td>26</td>\n",
       "      <td>80.625000</td>\n",
       "      <td>84.375000</td>\n",
       "      <td>74.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>2014-08-06</td>\n",
       "      <td>32</td>\n",
       "      <td>67.083333</td>\n",
       "      <td>64.833333</td>\n",
       "      <td>73.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>2014-08-07</td>\n",
       "      <td>34</td>\n",
       "      <td>53.142857</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>74.408571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>2014-08-08</td>\n",
       "      <td>16</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>36.428571</td>\n",
       "      <td>73.380000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1503 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Reported Incidents   Humidity  Cloudiness  Max_Temp_(F)\n",
       "0    2018-01-01                  30  54.291667    9.250000      2.655000\n",
       "1    2018-01-02                  28  66.750000    6.458333     -0.120000\n",
       "2    2018-01-03                  37  66.833333   60.416667     12.780000\n",
       "3    2018-01-04                  32  60.125000   31.208333     11.355000\n",
       "4    2018-01-05                  34  59.750000   11.708333      7.230000\n",
       "5    2018-01-06                  24  54.833333   11.625000      8.730000\n",
       "6    2018-01-07                  41  62.000000   62.958333     17.955000\n",
       "7    2018-01-08                  37  86.875000   71.333333     35.355000\n",
       "8    2018-01-09                  32  91.375000   54.708333     32.430000\n",
       "9    2018-01-10                  32  93.208333   81.958333     38.730000\n",
       "10   2018-01-11                  25  89.125000   90.000000     57.780000\n",
       "11   2018-01-12                  42  84.458333   90.000000     30.180000\n",
       "12   2018-01-13                  30  67.166667   56.791667     17.805000\n",
       "13   2018-01-14                  32  67.291667   20.166667     13.080000\n",
       "14   2018-01-15                  21  82.958333   84.208333     20.955000\n",
       "15   2018-01-16                  24  76.916667   86.875000     17.955000\n",
       "16   2018-01-17                  19  79.125000    9.500000     16.155000\n",
       "17   2018-01-18                  22  72.000000   14.826087     22.353913\n",
       "18   2018-01-19                  25  67.708333   12.500000     32.805000\n",
       "19   2018-01-20                  34  71.958333   28.083333     40.605000\n",
       "20   2018-01-21                  36  91.041667   90.000000     42.405000\n",
       "21   2018-01-22                  29  94.000000   86.666667     50.655000\n",
       "22   2018-01-23                  34  90.791667   73.291667     38.355000\n",
       "23   2018-01-24                  20  82.833333   90.000000     30.255000\n",
       "24   2018-01-25                  26  76.958333   46.125000     33.030000\n",
       "25   2018-01-26                  27  78.750000   16.041667     44.355000\n",
       "26   2018-01-27                  26  49.833333   64.208333     50.805000\n",
       "27   2018-01-28                  27  77.291667   23.291667     38.955000\n",
       "28   2018-01-29                  24  81.666667   90.000000     31.230000\n",
       "29   2018-01-30                  20  69.041667   32.041667     23.355000\n",
       "...         ...                 ...        ...         ...           ...\n",
       "1649 2014-07-08                  36  62.130435   64.347826     78.697391\n",
       "1650 2014-07-09                  25  58.833333   32.208333     73.680000\n",
       "1651 2014-07-10                  36  66.333333   17.625000     71.130000\n",
       "1652 2014-07-11                  38  50.260870   47.521739     73.552609\n",
       "1653 2014-07-12                  32  70.125000   82.916667     76.980000\n",
       "1654 2014-07-13                  24  74.833333   66.875000     78.405000\n",
       "1655 2014-07-14                  32  61.227273   56.181818     75.343636\n",
       "1656 2014-07-15                  22  62.458333   53.750000     65.744583\n",
       "1657 2014-07-16                  37  70.583333   51.583333     65.755833\n",
       "1658 2014-07-17                  14  62.625000   41.666667     68.547917\n",
       "1659 2014-07-18                  22  61.083333   52.583333     72.355000\n",
       "1660 2014-07-19                  33  55.208333   26.083333     74.146250\n",
       "1661 2014-07-20                  30  64.541667   49.250000     75.360417\n",
       "1662 2014-07-21                  26  66.750000   15.333333     78.529583\n",
       "1663 2014-07-22                  35  63.750000   19.291667     81.830417\n",
       "1664 2014-07-23                  33  70.791667   45.875000     75.037500\n",
       "1665 2014-07-24                  31  68.125000   10.500000     64.928750\n",
       "1666 2014-07-25                  32  65.333333   63.055556     68.667778\n",
       "1667 2014-07-26                  24  71.208333   66.750000     75.662500\n",
       "1668 2014-07-27                  23  70.714286   49.904762     80.236667\n",
       "1671 2014-07-30                  23  56.000000   46.000000     79.082000\n",
       "1672 2014-07-31                  33  62.782609   17.869565     73.829130\n",
       "1673 2014-08-01                  38  66.227273   49.409091     77.815000\n",
       "1674 2014-08-02                  42  72.250000   23.750000     69.526250\n",
       "1675 2014-08-03                  26  47.875000   68.125000     85.755000\n",
       "1676 2014-08-04                  31  61.714286   52.333333     78.780000\n",
       "1677 2014-08-05                  26  80.625000   84.375000     74.205000\n",
       "1678 2014-08-06                  32  67.083333   64.833333     73.155000\n",
       "1679 2014-08-07                  34  53.142857   81.428571     74.408571\n",
       "1680 2014-08-08                  16  64.285714   36.428571     73.380000\n",
       "\n",
       "[1503 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use to check outputs\n",
    "#weatherrobbery18nan\n",
    "#weatherrobbery18\n",
    "#weatherrobbery17nan\n",
    "#weatherrobbery17\n",
    "#weatherrobbery16nan\n",
    "#weatherrobbery16\n",
    "#weatherrobbery15nan\n",
    "#weatherrobbery15\n",
    "#weatherrobbery14nan\n",
    "#weatherrobbery14\n",
    "weatherrobberyall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
